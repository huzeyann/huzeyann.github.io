---
layout: about
title: about
permalink: /
description: huze

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <p>üìçPenn</p>
    <p><a href="mailto:%68%75%7A%65.%79%61%6E%6E@%67%6D%61%69%6C.%63%6F%6D"><i class="fas fa-envelope"> Email</i></a></p>
    <p><a href="https://github.com/huzeyann" target="_blank" title="GitHub"><i class="fab fa-github"> Github</i></a></p>
    <p><a href="https://twitter.com/HuzeYann" target="_blank" title="Twitter"><i class="fab fa-twitter"> Twitter</i></a></p>


news: false  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---

PhD student at University of Pennsylvania, co-advised by [James C. Gee](https://www.med.upenn.edu/apps/faculty/index.php/g5455356/p10656){:target="\_blank"} and [Jianbo Shi](https://www.cis.upenn.edu/~jshi/){:target="\_blank"}. 

I have been nerding out on <b>Brain Encoding Models</b> since we met. I work on computer vision and computational neuroscience.

before joining academia, I was at CNSS DevOps team. We had great fun in CTF and Hackathon.

<br/>

I play rhythm game and instruments when research doesn't work <small>(they doesn't work most of the time)</small>. My favorite: Blues Driver & Telecaster

<br/><br/><br/><br/><br/><br/><br/> 

<hr>

<h2>Softwares </h2>

I like Softwares, they are alive, you can play with them.

<font face="helvetica, ariel, 'sans serif'">
            <table cellspacing="15">
				<tbody>
                <tr>
                    <td width="40%" align="center">
                    <a href="https://ncut-pytorch.readthedocs.io/">
                        <video width="90%" controls="" muted="" autoplay="" loop="">
                        <source src="/assets/videos/ncut_video_sam_264_small.mp4" type="video/mp4">
                        </video>
                    </a> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>ncut-pytorch</b>: Nystr√∂m Normalized Cuts PyTorch <br><br>
                        <span style="font-size: 10pt;">
                        [<a href="https://huggingface.co/spaces/huzey/ncut-pytorch">Huggingface Demo</a>] <br>
                        [<a href="https://ncut-pytorch.readthedocs.io/">Python Package</a>] <br>
                        [<a href="https://ncut-pytorch.readthedocs.io/">Website</a>] <br>
                        [<a href="https://penno365-my.sharepoint.com/:p:/g/personal/huze_upenn_edu/ESmESKMkHONGm-UMYz1X2A4BmjlT4Qmlv63QaJq8Z1ButQ?e=gvr5e1">Slides</a>] <br>
                        [Paper (coming)]
                        <br>
                    </span></span></td>
                </tr>
                </tbody>
            </table>
            
</font>


<br/>
<hr>

<h2>Publications </h2>

This page only list publications with extra materials such as code and video. For a full list of publications please use <a href="https://scholar.google.com/citations?user=8yVLKyYAAAAJ">Google Scholar</a>

<font face="helvetica, ariel, 'sans serif'">
            <table cellspacing="15">
				<tbody>
                <tr>
                    <td width="30%" align="center">
                        <img width="225" align="middle" src="/assets/img/alignedcut.jpg" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>AlignedCut: Visual Concepts Discovery on Brain-Guided Universal Feature Space</b> <br>
                        <span style="font-size: 10pt;">
                        Huzheng Yang, James Gee*, Jianbo Shi*<br>
                        May. 2024 <br>
                        arxiv, <em>rejected by NeurIPS</em> <br>
                        [<a href="https://arxiv.org/abs/2406.18344">Paper</a>]
                        [<a href="https://penno365-my.sharepoint.com/:p:/g/personal/huze_upenn_edu/EdPlbbmV3Q9DmXKRIElcw5ABhOnNQctJSky6jcN7Au0elg?e=snyVLo">Slides</a>]
                        <br>
                    </span></span></td>
                </tr>
                <tr>
                    <td width="30%" align="center">
                        <img width="225" align="middle" src="assets/gif/brain_background.gif" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Brain Decodes Deep Nets</b> <br>
                        <span style="font-size: 10pt;">
                        Huzheng Yang, James Gee*, Jianbo Shi*<br>
                        Nov. 2023 <br>
                        CVPR'24, <b><em><a>highlight</a></em></b> <br>
                        [<a href="https://arxiv.org/abs/2312.01280">Paper</a>]
                        [<a href="https://huzeyann.github.io/brain-decodes-deep-nets">Webpage</a>]
                        [<a href="https://github.com/huzeyann/BrainDecodesDeepNets">GitHub</a>]
                        [<a href="https://penno365-my.sharepoint.com/:p:/g/personal/huze_upenn_edu/EVDLndCXy21LpKEelu_MVkMBK9dbFIhlI6VEQzOl4j6eLA?e=eED63x">Slides</a>]
                        [<a href="https://youtu.be/Qh49zQQCW1g">Talk online</a>]
                        <br>
                    </span></span></td>
                </tr>
                <tr>
                    <td width="30%" align="center">
                        <img width="225" align="middle" src="assets/custom_images/small_brain.gif" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Memory Encoding Model</b> <br>
                        <span style="font-size: 10pt;">
                        Huzheng Yang, James Gee*, Jianbo Shi*<br>
                        Aug. 2023 <br>
                        arxiv, <b><em><a style="color:DarkOrange;" href="http://algonauts.csail.mit.edu/archive.html">Algonauts 2023 challenge winner</a></em></b> <br>
                        [<a href="https://arxiv.org/abs/2308.01175">Paper</a>]
                        [<a href="https://huzeyann.github.io/mem">Webpage</a>]
                        [<a href="https://github.com/huzeyann/MemoryEncodingModel">GitHub</a>]
                        [<a href="https://penno365-my.sharepoint.com/:p:/g/personal/huze_upenn_edu/EewQz_XbSpJCtm63dl7WSSkBOeRDEfzGY8rcrwsmm5KvgA?e=Tw9hAv">Slides</a>]
                        [<a href="https://www.youtube.com/live/9Xh55mcWJeE?si=aCdlPM1MnBaainIF&t=3343">Talk CCN'23</a>]
                        <br>
                    </span></span></td>
                </tr>
                <tr>
                    <td width="30%" align="center">
                        <img width="225" align="middle" src="assets/custom_images/small_rm.gif" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Retinotopy Inspired Brain Encoding Model and the All-for-One Training Recipe</b> <br>
                        <span style="font-size: 10pt;">
                        Huzheng Yang, Jianbo Shi*, James Gee*<br>
                        May. 2023 <br>
                        arxiv, <em>rejected by NeurIPS</em> <br>
                        [<a href="https://arxiv.org/abs/2307.14021">Paper</a>]
                        [<a href="https://openreview.net/forum?id=DvRTU1whxF">Openreview</a>]
                        <br>
                    </span></span></td>
                </tr>
                <tr>
                    <td width="30%" align="center">
                        <img width="225" align="middle" src="assets/custom_images/me_fmri.jpg" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Upgrading Voxel-wise Encoding Model via Integrated Integration over Features and Brain Networks</b> <br>
                        <span style="font-size: 10pt;">
                        Yuanning Li*, Huzheng Yang*, Shi Gu<br>
                        Nov. 2022 <br>
                        Science Bulletin <br>
                        [<a href="https://www.sciencedirect.com/science/article/pii/S2095927324001373">Paper</a>]
                        [<a href="https://github.com/huzeyann/htROI-neural-encoding">GitHub</a>]
                        <br>
                    </span></span></td>
                </tr>
                <tr>
                    <td width="30%" align="center">
                        <img width="225" align="middle" src="assets/custom_images/forg.jpg" border="0"> &nbsp;
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Effective Ensemble of Deep Neural Networks Predicts Neural Responses to Naturalistic Videos</b> <br>
                        <span style="font-size: 10pt;">
                        Huzheng Yang, Shanghang Zhang, Yifan Wu, Yuanning Li*, Shi Gu*<br>
                        Aug. 2021 <br>
                        bioRxiv, <b><em><a style="color:DarkOrange;" href="http://algonauts.csail.mit.edu/2021/index.html">Algonauts 2021 challenge winner</a></em></b> <br>
                        [<a href="https://www.biorxiv.org/content/10.1101/2021.08.24.457581.abstract">Paper</a>]
                        [<a href="https://github.com/huzeyann/huze_algonauts21">GitHub</a>]
                        [<a href="https://www.youtube.com/watch?v=xtSh_XotVlo">Talk CCN'21</a>]
                        <br>
                    </span></span></td>
                </tr>



            </tbody></table>
            
</font>
